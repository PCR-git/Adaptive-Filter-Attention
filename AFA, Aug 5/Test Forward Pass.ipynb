{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b135f96",
   "metadata": {},
   "source": [
    "### Test forward pass of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935c4b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm # Loading bar\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19255d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from utils import complex_conj_transpose, batched_complex_conj_transpose, complex_exp, complex_exp_v2, complex_hadamard, complex_matmul, complex_division\n",
    "from utils import batched_complex_conj_transpose, batched_complex_hadamard, batched_complex_matmul, batched_complex_division\n",
    "from utils import batched_complex_exp, batched_complex_hadamard_full, batched_complex_matmul_full\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05d90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from dynamics import stochastic_LTI, construct_mapping\n",
    "from dynamics import get_nth_measurement, get_random_measurements\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62aa8352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from precision_attention import compute_residuals, compute_kernel_v1, compute_estimates_and_residuals_vectorized, get_time_diffs, compute_neg_kernel, clamp_exponent_arg\n",
    "from precision_attention import compute_kernel, batched_compute_estimates_and_residuals_vectorized, compute_estimates_and_residuals_irregular_times, compute_nu\n",
    "from precision_attention import compute_precision_v1\n",
    "from precision_attention import precise_attn, precise_attn_with_correction, precise_attn_full\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a3e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from model import compute_lambda_h\n",
    "from model import init_complex_matrix, build_nearly_identity, initialize_to_correct_model\n",
    "from model import init_weight_masks, apply_weight_masks\n",
    "from model import Complex_MSE_Loss, Batched_Complex_MSE_Loss, inverse_penalty\n",
    "from model import BatchedPrecisionAttentionBlock\n",
    "from model import HadamardLayer, TemporalNorm, TemporalWhiteningLayer\n",
    "from model import PrecisionNet_1layer, PrecisionNet\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5263f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import construct_random_mapping, construct_data, TrainDataset, create_train_loader\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2ac3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from training import plot_trajectory, compute_state_transition_matrix, plot_state_transition_matrix, plot_eigenvals, visualize_results\n",
    "from training import single_iter, single_epoch, hook_fn\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0d6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('DA')\n",
    "parser.add_argument('--gpu', type=int, default=0) # (Default: 0)\n",
    "args = parser.parse_args(args=[])\n",
    "args.device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "print(args.device)\n",
    "\n",
    "torch.manual_seed(2025)\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40092f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a stable 2D linear system:\n",
    "D1 = torch.zeros(2,2,2).to(args.device) # Diagonal matrix\n",
    "S1 = torch.zeros(2,2,2).to(args.device) # Unitary matrix\n",
    "Si1 = torch.zeros(2,2,2).to(args.device) # Inverse of unitary matrix\n",
    "D1[0] = torch.tensor([[-0.1, 0.0], [0.0, -0.1]]).to(args.device)\n",
    "D1[1] = torch.tensor([[-1.0, 0.0], [0.0, 1.0]]).to(args.device)\n",
    "S1[0] = torch.tensor([[1.0, 1.0], [1.0, 1.0]]).to(args.device)\n",
    "S1[1] = torch.tensor([[-1.0, 1.0], [0.0, 0.0]]).to(args.device)\n",
    "Si1[0] = 0.5*torch.tensor([[0.0, 1.0], [0.0, 1.0]]).to(args.device)\n",
    "Si1[1] = 0.5*torch.tensor([[1.0, -1.0], [-1.0, 1.0]]).to(args.device)\n",
    "\n",
    "D1 = D1.unsqueeze(1)\n",
    "S1 = S1.unsqueeze(1)\n",
    "Si1 = Si1.unsqueeze(1)\n",
    "\n",
    "A = complex_matmul(S1,complex_matmul(D1,Si1))[0] # State transition matrix\n",
    "\n",
    "sigma_process = 0.0\n",
    "sigma_process_0 = 0.0\n",
    "sigma_measure = 0.1\n",
    "\n",
    "args.m = 2 # Dimension of system\n",
    "args.tf = 10 # Final time\n",
    "args.dt = 0.01 # Time step size\n",
    "args.N_t = int(args.tf/args.dt) + 1 # Number of time steps\n",
    "args.seq_len = args.N_t\n",
    "\n",
    "t_v = torch.linspace(0, args.tf, args.N_t).to(args.device) # Vector of times\n",
    "\n",
    "x0 = (torch.randn(args.m)*10).unsqueeze(0).unsqueeze(-1).to(args.device) # Initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283859ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true, X_measure_full = stochastic_LTI(A, x0, args.N_t, args, sigma_process=sigma_process, sigma_process_0=sigma_process_0, sigma_measure = sigma_measure) # Simulate system\n",
    "\n",
    "idxs, t_measure, X_measure = get_nth_measurement(X_measure_full, t_v, args.N_t, n=10)\n",
    "\n",
    "X = torch.zeros((2,X_measure.size()[0], X_measure.size()[1], X_measure.size()[2])).to(args.device)\n",
    "X[0] = X_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed095c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass of batched attention block\n",
    "\n",
    "inputs = X[:,:,:-1]\n",
    "outputs = X[:,:,1:]\n",
    "\n",
    "args.embed_dim = 256\n",
    "args.num_heads = 1\n",
    "args.head_dim = int(args.embed_dim/args.num_heads)\n",
    "args.d_k = args.head_dim # Key and query embedding dimension\n",
    "args.d_v = args.head_dim # Value embedding dimension\n",
    "\n",
    "args.nu = 1.0\n",
    "\n",
    "args.seq_len = int(args.tf/args.dt) # Number of time steps\n",
    "\n",
    "t_v = torch.linspace(0, args.tf, args.seq_len + 1).to(args.device)[:-1] # Vector of times\n",
    "\n",
    "model0 = PrecisionNet_1layer(args).to(args.device)\n",
    "\n",
    "# model0.forward(inputs,t_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59357d03",
   "metadata": {},
   "source": [
    "Test forward pass of full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f8db4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.t_equal = 1\n",
    "args.tanh = 0\n",
    "args.weight_mask = 1\n",
    "args.nu_adaptive = 0\n",
    "\n",
    "args.embed_dim = 256\n",
    "args.num_heads = 1\n",
    "args.head_dim = int(args.embed_dim/args.num_heads)\n",
    "args.d_k = args.head_dim # Key and query embedding dimension\n",
    "args.d_v = args.head_dim # Value embedding dimension\n",
    "\n",
    "args.nu = 1.0\n",
    "args.tf = 10.0 # Final time\n",
    "args.dt = 0.01 # Time step size\n",
    "# args.seq_len = int(tf/args.dt) # Number of time steps\n",
    "args.N_t = int(args.tf/args.dt) # Number of time steps\n",
    "args.seq_len = 100\n",
    "args.n = 10\n",
    "\n",
    "args.alpha = 1.0\n",
    "args.beta = 0.0\n",
    "args.delta = 1.0\n",
    "args.eta = 0.0\n",
    "\n",
    "# t_v = torch.linspace(0, args.tf, args.seq_len + 1).to(args.device)[:-1] # Vector of times\n",
    "t_v = torch.linspace(0, args.tf, args.N_t+1).to(args.device) # Vector of times\n",
    "\n",
    "model0 = PrecisionNet_1layer(args).to(args.device)\n",
    "\n",
    "# loss = nn.L1Loss()\n",
    "# loss = nn.L2Loss()\n",
    "loss = Batched_Complex_MSE_Loss()\n",
    "lr = 1E-4\n",
    "params_list = list(model0.parameters())\n",
    "optimizer = torch.optim.Adam(params_list, lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "Pu, Pd, R1, R1i = construct_random_mapping(S1, Si1, args)\n",
    "\n",
    "x0 = (torch.randn(args.m)*10).unsqueeze(0).unsqueeze(-1).to(args.device) # Initial condition\n",
    "#     X_true, X_measure = stochastic_LTI(A, x0, Npts, args, sigma_process=sigma_process, sigma_process_0=sigma_process_0, sigma_measure=sigma_measure) # Simulate system\n",
    "X_true, X_measure_full = stochastic_LTI(A, x0, args.N_t+1, args, sigma_process=sigma_process, sigma_process_0=sigma_process_0, sigma_measure = sigma_measure) # Simulate system\n",
    "idxs, t_measure, X_measure = get_nth_measurement(X_measure_full, t_v, args.N_t+1, n=10)\n",
    "\n",
    "X_measure_c = torch.zeros((2,X_measure.size()[0], X_measure.size()[1], X_measure.size()[2])).to(args.device)\n",
    "X_measure_c[0].size()\n",
    "X_measure_c[0] = X_measure\n",
    "X_high = complex_matmul(Pu,X_measure_c) # Map to higher dim\n",
    "\n",
    "#     X_random = torch.matmul(R1,X_high) # Map to random basis\n",
    "X_random = complex_matmul(R1,X_high) # Map to random basis\n",
    "X_random, X_high, X_true, X_measure, t_measure = construct_data(A, Pu, Pd, R1, R1i, args.N_t+1, t_v, sigma_process, sigma_process_0, sigma_measure, args)\n",
    "X = torch.matmul(R1i,X_random.unsqueeze(-1)).unsqueeze(0).squeeze(-1)\n",
    "\n",
    "inputs = X[:, :, :-1]\n",
    "outputs = X[:, :, 1:]\n",
    "\n",
    "optimizer.zero_grad() # Zero out gradients\n",
    "\n",
    "# est, out, Q_ij, X_ij_hat_all = model0(inputs, t_v)\n",
    "est, out, Q_ij, X_ij_hat_all, lambda_h = model0(inputs, t_measure.unsqueeze(0))\n",
    "\n",
    "loss_i = loss(out, outputs)\n",
    "\n",
    "loss_i.backward()\n",
    "\n",
    "torch.nn.utils.clip_grad_norm_(params_list, 1)\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285e31aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02706766128540039\n"
     ]
    }
   ],
   "source": [
    "args.reconstruct = 0\n",
    "args.latent_loss = 0\n",
    "args.nu_adaptive = 0\n",
    "\n",
    "# Test single_iter\n",
    "\n",
    "args.penalty_weight = 0\n",
    "\n",
    "args.embed_dim = 256\n",
    "args.d_v = args.embed_dim\n",
    "args.nu = 1.0\n",
    "args.tf = 10.0 # Final time\n",
    "args.dt = 0.01 # Time step size\n",
    "args.N_t = int(args.tf/args.dt) # Number of time steps\n",
    "n = 10 # nth measurement\n",
    "args.seq_len = int(args.N_t/n)\n",
    "\n",
    "t_v = torch.linspace(0, args.tf, args.N_t+1).to(args.device) # Vector of times\n",
    "\n",
    "model0 = PrecisionNet_1layer(args).to(args.device)\n",
    "\n",
    "# loss = nn.L1Loss()\n",
    "# loss = nn.L2Loss()\n",
    "# loss = ComplexL2Loss()\n",
    "loss = Batched_Complex_MSE_Loss()\n",
    "loss_p = Complex_MSE_Loss()\n",
    "lr = 1E-4\n",
    "params_list = list(model0.parameters())\n",
    "optimizer = torch.optim.Adam(params_list, lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "Pu, Pd, R1, R1i = construct_random_mapping(S1, Si1, args)\n",
    "\n",
    "# X_true, X_measure_full = stochastic_LTI(A, x0, args.N_t+1, args, sigma_process=sigma_process, sigma_process_0=sigma_process_0, sigma_measure = sigma_measure) # Simulate system\n",
    "# idxs, t_measure, X_measure = get_nth_measurement(X_measure_full, t_v, args.N_t+1, n=n)\n",
    "\n",
    "# X_measure_c = torch.zeros((2,X_measure.size()[0], X_measure.size()[1], X_measure.size()[2])).to(args.device)\n",
    "# X_measure_c[0].size()\n",
    "# X_measure_c[0] = X_measure\n",
    "# X_high = complex_matmul(Pu,X_measure_c) # Map to higher dim\n",
    "\n",
    "#     X_random = torch.matmul(R1,X_high) # Map to random basis\n",
    "# X_random = complex_matmul(R1,X_high) # Map to random basis\n",
    "X_random, X_high, X_true, X_measure, t_measure = construct_data(A, Pu, Pd, R1, R1i, args.N_t+1, t_v, sigma_process, sigma_process_0, sigma_measure, args)\n",
    "X = torch.matmul(R1i,X_random.unsqueeze(-1)).unsqueeze(0).squeeze(-1)\n",
    "\n",
    "inputs = X[:, :, :-1]\n",
    "outputs = X[:, :, 1:]\n",
    "\n",
    "start = time.time()\n",
    "# single_iter(model0, optimizer, loss, inputs, outputs, t_v, args)\n",
    "single_iter(model0, optimizer, loss, loss_p, inputs, outputs, t_measure.unsqueeze(0), args)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172230b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
