{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cf8fe9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ComplexLinear' from 'model' (C:\\Users\\Pracioppo\\Desktop\\Peter DynAttn Proj\\model\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprecision_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_factorized_kernels, compute_weighted_residual_norm\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_lambda_h, init_complexlinear, init_complex_matrix, init_weight_masks, apply_weight_masks, apply_net_weight_masks\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexLinear\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ComplexLinear' from 'model' (C:\\Users\\Pracioppo\\Desktop\\Peter DynAttn Proj\\model\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import batched_complex_matmul, batched_complex_hadamard, batched_complex_exp, batched_complex_matmul_full\n",
    "\n",
    "from precision_attention import compute_exp_kernel\n",
    "from precision_attention import batched_compute_estimates_and_residuals_vectorized, compute_estimates_and_residuals_irregular_times\n",
    "from precision_attention import compute_precision, compute_precision_tanh, compute_covariance_kernel, build_covariance_from_kernel\n",
    "from precision_attention import build_factorized_kernels, compute_weighted_residual_norm\n",
    "\n",
    "from model import compute_lambda_h, init_complexlinear, init_complex_matrix, init_weight_masks, apply_weight_masks, apply_net_weight_masks\n",
    "from model import ComplexLinear\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef923b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedPrecisionAttentionBlock(nn.Module):\n",
    "    def __init__(self, head_dim, args):\n",
    "        \"\"\"\n",
    "        Initializes the batched precision-weighted attention block.\n",
    "\n",
    "        Parameters:\n",
    "            W_q, W_k, W_v, W_o (torch.Tensor): Learnable weight matrices (query, key, value, and output).\n",
    "            args: Additional model/system parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        if args.d_v == None or args.d_k == None:\n",
    "            self.d_v = head_dim\n",
    "            self.d_k = head_dim\n",
    "        else:\n",
    "            self.d_v = args.d_v\n",
    "            self.d_k = args.d_k\n",
    "\n",
    "        self.W_q = ComplexLinear(args.d_e, args.d_k)\n",
    "        self.W_k = ComplexLinear(args.d_e, args.d_k)\n",
    "        self.W_v = ComplexLinear(args.d_e, args.d_v)\n",
    "#         self.W_e = ComplexLinear(args.d_e, args.d_v)\n",
    "        self.W_p = ComplexLinear(args.d_e, args.d_v)\n",
    "#         self.W_r = ComplexLinear(args.d_e, args.d_v)\n",
    "\n",
    "        ################################################\n",
    "\n",
    "        self.complex_identity = torch.stack((torch.eye(self.d_v, self.d_v),torch.zeros(self.d_v, self.d_v))).unsqueeze(1).to(args.device)\n",
    "\n",
    "        sqrt_dv = torch.sqrt(torch.tensor(self.d_v))\n",
    "        \n",
    "        ######################\n",
    "        \n",
    "        lambda_r = torch.randn(int(self.d_v/2))\n",
    "        lambda_i = torch.randn(int(self.d_v/2))\n",
    "        self.lambda1 = nn.Parameter(torch.stack((lambda_r,lambda_i)).unsqueeze(-1)) # Stack and scale by time interval\n",
    "        self.lambda_h = torch.zeros(2,self.head_dim,1).to(args.device) # Initialize full eigenvalue array\n",
    "\n",
    "        self.lambda_Omega_sqrt = nn.Parameter(torch.randn(1,self.d_v,1)/sqrt_dv) # Process covariance\n",
    "        self.lambda_Gamma_sqrt = nn.Parameter(torch.randn(1,self.d_v,1)/sqrt_dv) # Measurement covariance\n",
    "\n",
    "        ######################\n",
    "        \n",
    "        self.noise_threshold = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        self.tau = nn.Parameter(torch.tensor(1.0))\n",
    "        self.nu = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    #     self.lambda_C = nn.Parameter(torch.randn(1,args.d_v,1)/sqrt_dv) # Measurement matrix\n",
    "        self.lambda_C = torch.ones(1,self.d_v,1).to(args.device) # Output matrix\n",
    "\n",
    "        Wqi, bqi = init_complex_matrix(args.d_e, args.d_k, bias=True)\n",
    "        Wki, bki = init_complex_matrix(args.d_e, args.d_k, bias=True)\n",
    "        Wvi, bvi = init_complex_matrix(args.d_e, args.d_v, bias=True)\n",
    "#         Wei, bei = init_complex_matrix(args.d_e, args.d_v, bias=True)\n",
    "        Wpi, bpi = init_complex_matrix(args.d_e, args.d_v, bias=True)\n",
    "        init_complexlinear(self.W_q, Wqi, bqi)\n",
    "        init_complexlinear(self.W_k, Wki, bki)\n",
    "        init_complexlinear(self.W_v, Wvi, bvi)\n",
    "#         init_complexlinear(self.W_e, Wei, bei)\n",
    "        init_complexlinear(self.W_p, Wpi, bpi)\n",
    "\n",
    "        ################################################\n",
    "\n",
    "        self.args = args\n",
    "\n",
    "        self.causal_mask = torch.tril(torch.ones(args.seq_len, args.seq_len)).view(1, args.seq_len, args.seq_len, 1, 1).to(args.device) # Causal attention mask\n",
    "\n",
    "        # Relative weighting of attention (alpha) and residual (beta) connections (useful for diagnosis)\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.0))\n",
    "        self.beta = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        # Relative weighting of estimate (delta) and prediction (eta) in output\n",
    "        self.delta = nn.Parameter(torch.tensor(0.0))\n",
    "        self.eta = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "        ############################################\n",
    "\n",
    "        # Create masks for parameter matrices (used for testing)\n",
    "        init_weight_masks(self, args)\n",
    "\n",
    "        ############################################\n",
    "\n",
    "    def forward(self, Z_q, Z_k, Z_v, t_measure_all):\n",
    "        \"\"\"\n",
    "        Forward pass through the precision-weighted attention block.\n",
    "\n",
    "        Parameters:\n",
    "            X (torch.Tensor): Input data.\n",
    "            lambda_h (torch.Tensor): Diagonal of state transition matrix.\n",
    "            lambda_Omega (torch.Tensor): Process noise covariance.\n",
    "            lambda_C (torch.Tensor): Measurement output matrix.\n",
    "            lambda_Gamma (torch.Tensor): Measurement noise covariance.\n",
    "            t_measure_all (torch.Tensor): Time differences vector, for each trajectory in batch.\n",
    "\n",
    "        Returns:\n",
    "            out (torch.Tensor): Output tensor.\n",
    "            Q_ij (torch.Tensor): Normalized attention weights.\n",
    "            X_ij_hat_all (torch.Tensor): Estimated values.\n",
    "        \"\"\"\n",
    "        \n",
    "        ############ (Masking; used for testing) ###########\n",
    "#         lambda_h, lambda_Omega, lambda_Gamma, W_q, W_k, W_v, W_p, W_r, W_e, W_q_b, W_k_b, W_v_b, W_p_b, W_r_b, W_e_b = apply_weight_masks(self, self.args)\n",
    "        apply_net_weight_masks(self)\n",
    "        ####################################################\n",
    "\n",
    "        lambda_h = compute_lambda_h(self.lambda1,self.args) # JUST FOR TESTING\n",
    "\n",
    "        # Take absolute value of noise parameters to ensure positive definiteness / non-negativeness\n",
    "        lambda_Omega = self.lambda_Omega_sqrt**2 + self.args.epsilon # Process noise matrix\n",
    "        lambda_Gamma = self.lambda_Gamma_sqrt**2 + self.args.epsilon # Measurement noise matrix\n",
    "\n",
    "        # Project input into Q, K, V        \n",
    "        Q = self.W_q(Z_q).unsqueeze(-1)\n",
    "        K = self.W_k(Z_k).unsqueeze(-1)\n",
    "        V = self.W_v(Z_v).unsqueeze(-1)\n",
    "\n",
    "        if len(t_measure_all.size()) > 1:\n",
    "            t_measure = t_measure_all[0,:-1]\n",
    "        else:\n",
    "            t_measure = t_measure_all[:,:-1]\n",
    "\n",
    "        ########################################################\n",
    "\n",
    "        K_exp, K_exp2 = compute_exp_kernel(lambda_h, t_measure)\n",
    "\n",
    "        mat_exp = K_exp[:, -(self.args.seq_len+1), :, :] # Get matrix exponential for next-state prediction\n",
    "\n",
    "        K_cov = compute_covariance_kernel(lambda_h, lambda_Omega, lambda_Gamma, K_exp, t_measure, self.args, lambda_C=self.lambda_C)\n",
    "\n",
    "        V_avg_ij = build_avg_covariance_from_kernel(K_cov, args).squeeze()\n",
    "\n",
    "        V_k, V_v, U_q, U_k, U_v = build_factorized_kernels(exp_f, exp_b, exp_f, exp_b, Q, K, V)\n",
    "\n",
    "        R_qk_abs = compute_weighted_residual_norm(V_k, U_k, U_q)\n",
    "\n",
    "        base_attn_scores = (self.noise_threshold**2 + self.args.epsilon) * V_avg_ij + R_qk_abs\n",
    "\n",
    "        attention_scores = - self.tau**2 * torch.log(base_attn_scores).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        attention_scores.masked_fill_(self.causal_mask == 0, float('-inf')) # Set to -infinity where mask is 0\n",
    "        attention_scores_normalized = torch.softmax(attention_scores, dim=2)\n",
    "\n",
    "        # Complex-valued attention matrix\n",
    "        Q_ij = torch.stack((attention_scores_normalized, torch.zeros_like(attention_scores_normalized)),dim=1) # Add zero imaginary part to unnormalized attention\n",
    "\n",
    "        # Estimate in diagonalized space\n",
    "        est_inner = batched_complex_matmul_full(Q_ij.squeeze(-1).squeeze(-1), U_v).unsqueeze(-1) # Multiply by Values to get output\n",
    "\n",
    "        est_v = V_v.unsqueeze(-1) * est_inner\n",
    "\n",
    "        # Add residual connection\n",
    "        # est_eigenbasis = est_v # No residual connection\n",
    "        est_latent = (1-torch.sigmoid(self.delta))*V + torch.sigmoid(self.delta)*est_v\n",
    "\n",
    "        # Get prediction in diagonalized space\n",
    "        pred_p = batched_complex_hadamard(mat_exp, est_latent)\n",
    "\n",
    "        # Multiply by output matrix to get output prediction\n",
    "        pred = self.W_p(pred_p.squeeze(-1))\n",
    "        #     pred = batched_complex_matmul(self.W_p, batched_complex_hadamard(lambda_h, X_v))*self.args.dt + X_v # JUST FOR TESTING\n",
    "\n",
    "        # Output is a linear combination of estimate and prediction\n",
    "        out = pred\n",
    "\n",
    "        est_latent = est_latent.squeeze(-1)\n",
    "        out = out.squeeze(-1)\n",
    "        X_ij_hat_all = X_ij_hat_all.squeeze(-1)\n",
    "\n",
    "        return est_latent, out, Q_ij, V_v, U_v, lambda_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ (Masking; used for testing) ###########\n",
    "apply_net_weight_masks(self)\n",
    "####################################################\n",
    "\n",
    "lambda_h = compute_lambda_h(self.lambda1,self.args) # JUST FOR TESTING\n",
    "\n",
    "# Take absolute value of noise parameters to ensure positive definiteness / non-negativeness\n",
    "lambda_Omega = self.lambda_Omega_sqrt**2 + self.args.epsilon # Process noise matrix\n",
    "lambda_Gamma = self.lambda_Gamma_sqrt**2 + self.args.epsilon # Measurement noise matrix\n",
    "\n",
    "# Project input into Q, K, V        \n",
    "Q = self.W_q(Z_q).unsqueeze(-1)\n",
    "K = self.W_k(Z_k).unsqueeze(-1)\n",
    "V = self.W_v(Z_v).unsqueeze(-1)\n",
    "\n",
    "if len(t_measure_all.size()) > 1:\n",
    "    t_measure = t_measure_all[0,:-1]\n",
    "else:\n",
    "    t_measure = t_measure_all[:,:-1]\n",
    "\n",
    "########################################################\n",
    "\n",
    "K_exp, K_exp2 = compute_exp_kernel(lambda_h, t_measure)\n",
    "\n",
    "mat_exp = K_exp[:, -(self.args.seq_len+1), :, :] # Get matrix exponential for next-state prediction\n",
    "\n",
    "K_cov = compute_covariance_kernel(lambda_h, lambda_Omega, lambda_Gamma, K_exp, t_measure, self.args, lambda_C=self.lambda_C)\n",
    "\n",
    "V_avg_ij = build_avg_covariance_from_kernel(K_cov, args).squeeze()\n",
    "\n",
    "V_k, V_v, U_q, U_k, U_v = build_factorized_kernels(exp_f, exp_b, exp_f, exp_b, Q, K, V)\n",
    "\n",
    "R_qk_abs = compute_weighted_residual_norm(V_k, U_k, U_q)\n",
    "\n",
    "base_attn_scores = (self.noise_threshold**2 + self.args.epsilon) * V_avg_ij + R_qk_abs\n",
    "\n",
    "attention_scores = - self.tau**2 * torch.log(base_attn_scores).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "attention_scores.masked_fill_(self.causal_mask == 0, float('-inf')) # Set to -infinity where mask is 0\n",
    "attention_scores_normalized = torch.softmax(attention_scores, dim=2)\n",
    "\n",
    "# Complex-valued attention matrix\n",
    "Q_ij = torch.stack((attention_scores_normalized, torch.zeros_like(attention_scores_normalized)),dim=1) # Add zero imaginary part to unnormalized attention\n",
    "\n",
    "# Estimate in diagonalized space\n",
    "est_inner = batched_complex_matmul_full(Q_ij.squeeze(-1).squeeze(-1), U_v).unsqueeze(-1) # Multiply by Values to get output\n",
    "\n",
    "est_v = V_v.unsqueeze(-1) * est_inner\n",
    "\n",
    "# Add residual connection\n",
    "# est_eigenbasis = est_v # No residual connection\n",
    "est_latent = (1-torch.sigmoid(self.delta))*V + torch.sigmoid(self.delta)*est_v\n",
    "\n",
    "# Get prediction in diagonalized space\n",
    "pred_p = batched_complex_hadamard(mat_exp, est_latent)\n",
    "\n",
    "# Multiply by output matrix to get output prediction\n",
    "pred = self.W_p(pred_p.squeeze(-1))\n",
    "#     pred = batched_complex_matmul(self.W_p, batched_complex_hadamard(lambda_h, X_v))*self.args.dt + X_v # JUST FOR TESTING\n",
    "\n",
    "# Output is a linear combination of estimate and prediction\n",
    "out = pred\n",
    "\n",
    "est_latent = est_latent.squeeze(-1)\n",
    "out = out.squeeze(-1)\n",
    "X_ij_hat_all = X_ij_hat_all.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880eaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
