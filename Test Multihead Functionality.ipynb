{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd4d609",
   "metadata": {},
   "source": [
    "## Test Multihead Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe93406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm # Loading bar\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fa7de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from utils import complex_conj_transpose, batched_complex_conj_transpose, complex_exp, complex_exp_v2, complex_hadamard, complex_matmul, complex_division\n",
    "from utils import batched_complex_conj_transpose, batched_complex_hadamard, batched_complex_matmul, batched_complex_division\n",
    "from utils import batched_complex_exp, batched_complex_hadamard_full, batched_complex_matmul_full\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71df24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from dynamics import stochastic_LTI, DynamicSim\n",
    "from dynamics import construct_mapping\n",
    "from dynamics import get_nth_measurement, get_random_measurements\n",
    "from dynamics import linear_spiral, linear_spiral_3D, Lorenz, rand_coupling_matrix, Van_der_Pol_osc\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641633f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from precision_attention import compute_residuals, compute_kernel_v1, compute_estimates_and_residuals_vectorized, get_time_diffs, compute_neg_kernel, clamp_exponent_arg\n",
    "from precision_attention import compute_kernel, batched_compute_estimates_and_residuals_vectorized, compute_estimates_and_residuals_irregular_times, compute_nu\n",
    "from precision_attention import compute_precision_v1\n",
    "# from precision_attention import precise_attn, precise_attn_with_correction, precise_attn_full\n",
    "from precision_attention import compute_precision, compute_precision_tanh\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64f961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from model import compute_lambda_h\n",
    "from model import init_complex_matrix, build_nearly_identity, initialize_to_correct_model\n",
    "from model import init_weight_masks, apply_weight_masks\n",
    "from model import Complex_MSE_Loss, Batched_Complex_MSE_Loss, inverse_penalty\n",
    "from model import BatchedPrecisionAttentionBlock\n",
    "from model import HadamardLayer, TemporalNorm, TemporalWhiteningLayer\n",
    "from model import PrecisionNet_1layer, PrecisionNet\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60f530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import construct_random_mapping, construct_data, TrainDataset, create_train_loader\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_trajectory, compute_state_transition_matrix, plot_state_transition_matrix, plot_eigenvals, visualize_results\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae7a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from training import single_iter, single_epoch, hook_fn\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0bb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('DA')\n",
    "parser.add_argument('--gpu', type=int, default=0) # (Default: 0)\n",
    "args = parser.parse_args(args=[])\n",
    "args.device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "print(args.device)\n",
    "\n",
    "torch.manual_seed(2025)\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9d1e0",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac1df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dynamical system\n",
    "\n",
    "# # Normal system\n",
    "# D1 = torch.zeros(2,2,2).to(args.device) # Diagonal matrix\n",
    "# D1[0] = torch.tensor([[-0.1, 0.0], [0.0, -0.1]]).to(args.device)\n",
    "# D1[1] = torch.tensor([[-1.0, 0.0], [0.0, 1.0]]).to(args.device)\n",
    "# # S1 = torch.zeros(2,2,2).to(args.device)\n",
    "# # S1[0] = torch.tensor(([1.0,1.0],[0.0,0.0]))\n",
    "# # S1[1] = torch.tensor(([0.0,0.0],[1.0,-1.0]))\n",
    "# # S1 = U/np.sqrt(2)\n",
    "# alpha = np.random.uniform(low=0.0, high=1.0)*2*np.pi\n",
    "# beta = np.random.uniform(low=0.0, high=1.0)*2*np.pi\n",
    "# S1 = construct_special_2D_unitary(alpha=alpha, beta=beta)\n",
    "# Si1 = complex_conj_transpose(S1)\n",
    "\n",
    "# Stable 2D linear system (in diagonalized form):\n",
    "D1 = torch.zeros(2,2,2).to(args.device) # Diagonal matrix\n",
    "S1 = torch.zeros(2,2,2).to(args.device) # RHS matrix\n",
    "Si1 = torch.zeros(2,2,2).to(args.device) # Inverse of RHS matrix\n",
    "D1[0] = torch.tensor([[-0.1, 0.0], [0.0, -0.1]]).to(args.device)\n",
    "D1[1] = torch.tensor([[-1.0, 0.0], [0.0, 1.0]]).to(args.device)\n",
    "# D1[0] = torch.tensor([[-0.1, 0.0], [0.0, -0.5]]).to(args.device)\n",
    "# D1[1] = torch.tensor([[-0.0, 0.0], [0.0, 0.0]]).to(args.device)\n",
    "S1[0] = torch.tensor([[1.0, 1.0], [1.0, 1.0]]).to(args.device)\n",
    "S1[1] = torch.tensor([[-1.0, 1.0], [0.0, 0.0]]).to(args.device)\n",
    "Si1[0] = 0.5*torch.tensor([[0.0, 1.0], [0.0, 1.0]]).to(args.device)\n",
    "Si1[1] = 0.5*torch.tensor([[1.0, -1.0], [-1.0, 1.0]]).to(args.device)\n",
    "A = complex_matmul(S1,complex_matmul(D1,Si1))[0].unsqueeze(0)\n",
    "params = [D1, S1, Si1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "125c440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "args.cr_max = 2\n",
    "args.cr_min = 0\n",
    "\n",
    "args.t_equal = 1 # Equal time intervals? (0 or 1)\n",
    "\n",
    "args.m = 2 # Dimension of simulated system\n",
    "# args.embed_dim = 2 # Embedding dimension\n",
    "args.embed_dim = 256 # Embedding dimension\n",
    "\n",
    "args.num_heads = 1\n",
    "args.head_dim = int(args.embed_dim/args.num_heads)\n",
    "\n",
    "#######################################\n",
    "\n",
    "# Key, query, value embedding dimensions are same as input embedding dimension\n",
    "args.d_k = args.head_dim\n",
    "args.d_v = args.head_dim\n",
    "\n",
    "# # Key, query, value embedding dimensions are half of input embedding dimension\n",
    "# args.d_k = int(args.head_dim/2) # Key and query embedding dimension\n",
    "# args.d_v = int(args.head_dim/2) # Value embedding dimension\n",
    "\n",
    "# # Key, query, value embedding dimensions are 2\n",
    "# args.d_k = 2 # Key and query embedding dimension\n",
    "# args.d_v = 2 # Value embedding dimension\n",
    "\n",
    "#######################################\n",
    "\n",
    "args.nu = 1.0 # Measurement weighting\n",
    "args.tf = 10.0 # Final time\n",
    "args.dt = 0.01 # Time step size\n",
    "args.n = 10 # nth measurement (ie use every nth point as a measurement)\n",
    "\n",
    "args.N_t = int(args.tf/args.dt) # Number of time steps\n",
    "args.seq_len = int(args.N_t/args.n) # Number of measurements\n",
    "# t_v = (torch.arange(args.N_t + args.n)*args.dt).to(args.device) # Array of time steps\n",
    "t_v = (torch.arange(args.N_t + args.n)*args.dt).to(args.device) # Array of time steps\n",
    "\n",
    "# Some scalar weights in model\n",
    "args.alpha = 1.0\n",
    "args.beta = 0.0\n",
    "args.delta = 1.0\n",
    "args.eta = 0.0\n",
    "\n",
    "# model = PrecisionAttentionBlock(args).to(args.device)\n",
    "model = PrecisionNet_1layer(args).to(args.device) # Define model\n",
    "params_list = list(model.parameters()) # Parameters list\n",
    "\n",
    "Pu, Pd, R1, R1i = construct_random_mapping(S1, Si1, args) # Get random matrices\n",
    "\n",
    "loss = Batched_Complex_MSE_Loss() # Loss\n",
    "loss_p = Complex_MSE_Loss() # Frobenius Norm Penalty\n",
    "# loss_p = Complex_Trace_Loss() # Trace Penalty\n",
    "lr = 1E-2 # Learning rate\n",
    "optimizer = torch.optim.Adam(params_list, lr=lr, betas=(0.9, 0.999)) # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5640002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 1000 # Number of epochs\n",
    "args.num_samp = 32 # Number of samples in train loader\n",
    "args.batch_size = 32 # Batch size\n",
    "args.num_its = int(args.num_samp/args.batch_size) # Number of iterations in an epoch\n",
    "args.save_epochs = 1 # Intervals of epochs to save model\n",
    "args.show_example_epochs = 4 # Number of epochs between displaying results so far\n",
    "args.n_example = 5 # Plot state estimates at n_example data points\n",
    "\n",
    "# args.penalty_weight = 0.1 # Penalty weight\n",
    "args.penalty_weight = 1.0 # Penalty weight\n",
    "args.weight_mask = 1 # Mask the weights? (0 or 1)\n",
    "args.tanh = 0 # Use tanh precision? (0 or 1)\n",
    "args.nu_adaptive = 0 # Use adaptive calculation of nu? (0 or 1)\n",
    "\n",
    "mean_epoch_losses = np.zeros(args.num_epochs)\n",
    "log_mean_epoch_losses = np.zeros(args.num_epochs)\n",
    "all_losses = np.zeros(args.num_epochs * args.num_samp)\n",
    "all_lambdas = np.zeros((args.num_epochs, 2, args.d_v))\n",
    "\n",
    "sigma_process = 0.0 # Process noise\n",
    "# sigma_process = 0.2 # Process noise\n",
    "sigma_process_0 = sigma_process # Initial process noise\n",
    "# sigma_measure = 0.1 # Measurement noise\n",
    "sigma_measure = 1.0 # Measurement noise\n",
    "\n",
    "# Build training dataset\n",
    "train_loader, train_dataset, X_true_all, X_measure_all, t_measure_all = create_train_loader(A, S1, Si1, Pu, Pd, R1, R1i, t_v, sigma_process, sigma_process_0, sigma_measure,args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b587b1",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c1f0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2, 100, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _split_heads(self, x: torch.Tensor, batch_size: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Splits the input tensor into multiple heads and prepares for attention.\n",
    "    (batch_size, 2, seq_len, embed_dim) -> (batch_size * num_heads, 2, seq_len, head_dim)\n",
    "    \"\"\"\n",
    "    seq_len = x.size(2)\n",
    "    # Reshape to (batch_size, 2, seq_len, num_heads, head_dim)\n",
    "    x = x.view(batch_size, 2, seq_len, self.num_heads, self.head_dim)\n",
    "    # Permute to (batch_size, num_heads, seq_len, head_dim)\n",
    "    x = x.permute(0, 3, 1, 2, 4)\n",
    "    # Reshape to (batch_size * num_heads, 2, seq_len, head_dim) for batched attention\n",
    "    return x.reshape(batch_size * self.num_heads, 2, seq_len, self.head_dim)\n",
    "\n",
    "def _combine_heads(self, x: torch.Tensor, batch_size: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Combines multiple attention heads back into a single tensor.\n",
    "    (batch_size * num_heads, 2, seq_len, head_dim) -> (batch_size, 2, seq_len, embed_dim)\n",
    "    \"\"\"\n",
    "    seq_len = x.size(2)\n",
    "    # Reshape to (batch_size, num_heads, 2, seq_len, head_dim)\n",
    "    x = x.view(batch_size, self.num_heads, 2, seq_len, self.head_dim)\n",
    "    # Permute to (batch_size, 2, seq_len, num_heads, head_dim)\n",
    "    x = x.permute(0, 2, 3, 1, 4)\n",
    "    # # Reshape to (batch_size, seq_len, embed_dim)\n",
    "    return x.reshape(batch_size, 2, seq_len, self.d_e)\n",
    "    \n",
    "args.num_heads = 4\n",
    "args.head_dim = int(args.embed_dim/args.num_heads)\n",
    "self=args\n",
    "x = X\n",
    "batch_size = args.batch_size\n",
    "\n",
    "X_q = X_k = X_v = X\n",
    "\n",
    "# x = _split_heads(self, X, args.batch_size)\n",
    "# # Xo = _combine_heads(self, x, args.batch_size)\n",
    "# # torch.sum(X-Xo)\n",
    "\n",
    "q_proj = nn.Linear(args.embed_dim, args.embed_dim)\n",
    "k_proj = nn.Linear(args.embed_dim, args.embed_dim)\n",
    "v_proj = nn.Linear(args.embed_dim, args.embed_dim)\n",
    "\n",
    "## DELETE ##################\n",
    "q_proj = q_proj.to(args.device)\n",
    "k_proj = k_proj.to(args.device)\n",
    "v_proj = v_proj.to(args.device)\n",
    "## DELETE ##################\n",
    "\n",
    "q = q_proj(X_q) # (B, S_q, E)\n",
    "k = k_proj(X_k)   # (B, S_k, E)\n",
    "v = v_proj(X_v) # (B, S_k, E)\n",
    " \n",
    "q = _split_heads(self, q, args.batch_size)\n",
    "k = _split_heads(self, k, args.batch_size)\n",
    "v = _split_heads(self, v, args.batch_size)\n",
    "\n",
    "attention_core = BatchedPrecisionAttentionBlock(args.head_dim, args).to(args.device)\n",
    "\n",
    "args.head_dim\n",
    "q.size()\n",
    "attention_core.W_q.size()\n",
    "_, out, _, _, _ = attention_core(q, k, v, t_measure_all)\n",
    "\n",
    "out.size()\n",
    "# Xo = _combine_heads(self, out, args.batch_size)\n",
    "\n",
    "# Xo.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23c7002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batched precision attention for experiments (original)\n",
    "\n",
    "# Pu, Pd, R1, R1i = construct_random_mapping(S1, Si1, args)\n",
    "# # train_loader, train_dataset, X_true_all, X_measure_all, t_measure = create_train_loader(A, S1, Si1, Pu, Pd, R1, R1i, t_v, sigma_process, sigma_process_0, sigma_measure,args)\n",
    "\n",
    "# for it, (train_data, X_true, X_measure, t_v_all) in enumerate(train_loader):\n",
    "\n",
    "#     inputs  = train_data[:, :, :-1]\n",
    "#     outputs = train_data[:, :, 1:]\n",
    "    \n",
    "#     break\n",
    "\n",
    "# X = inputs    \n",
    "# X_q = X\n",
    "# X_k = X\n",
    "# X_v = X\n",
    "\n",
    "# self = model.a1\n",
    "\n",
    "# ######################################################################################################\n",
    "# ######################################################################################################\n",
    "\n",
    "# self.lambda_h = compute_lambda_h(self.lambda1,self.args) # Get nonpositive complex conjugate eigenvalues\n",
    "\n",
    "# # Take absolute value of noise parameters to ensure positive definiteness / non-negativeness\n",
    "# self.lambda_Omega = self.lambda_Omega_sqrt**2 # Process noise matrix\n",
    "# self.lambda_Omega0 = self.lambda_Omega0_sqrt**2 # Initial process noise uncertainty matrix\n",
    "# self.lambda_Gamma = self.lambda_Gamma_sqrt**2 # Measurement noise matrix\n",
    "\n",
    "# ############ (Masking; used for testing) ###########\n",
    "# lambda_h, lambda_Omega, lambda_Omega0, lambda_Gamma, W_q, W_k, W_v, W_p, W_r, W_e, W_q_b, W_k_b, W_v_b, W_p_b, W_r_b, W_e_b = apply_weight_masks(self, self.args)\n",
    "# ####################################################\n",
    "\n",
    "# X_q = X_q.unsqueeze(-1)\n",
    "# X_k = X_k.unsqueeze(-1)\n",
    "# X_v = X_v.unsqueeze(-1)\n",
    "\n",
    "# # Project input into Q, K, V\n",
    "# #     Q = batched_complex_matmul(W_q, X_q)\n",
    "# #     K = batched_complex_matmul(W_k, X_k)\n",
    "# #     V = batched_complex_matmul(W_v, X_v)\n",
    "# Q = batched_complex_matmul(W_q, X_q) + W_q_b\n",
    "# K = batched_complex_matmul(W_k, X_k) + W_k_b\n",
    "# V = batched_complex_matmul(W_v, X_v) + W_v_b\n",
    "\n",
    "# #     R = batched_complex_matmul(W_r, X_v)\n",
    "\n",
    "# # G1 = torch.sigmoid(self.G1)\n",
    "# # G = torch.stack((G1,torch.zeros(self.args.seq_len,self.args.embed_dim,1)))\n",
    "# # IG = torch.stack((1 - G1,torch.zeros(self.args.seq_len,self.args.embed_dim,1)))\n",
    "\n",
    "# if len(t_measure_all.size()) > 1:\n",
    "#     t_measure = t_measure_all[0,:-1]\n",
    "# else:\n",
    "#     t_measure = t_measure_all[:,:-1]\n",
    "\n",
    "# # Functionality for possibly unequal time intervals\n",
    "# if self.args.t_equal == 1: # If equal time intervals\n",
    "#     K_exp, K_exp2 = compute_kernel(lambda_h, t_measure)\n",
    "#     X_ij_hat_all, R_qk_ij = batched_compute_estimates_and_residuals_vectorized(Q, K, V, K_exp, self.args)\n",
    "#     mat_exp = K_exp[:, -(self.args.seq_len+1), :, :] # Get matrix exponential for next-state prediction\n",
    "# else: # If unequal time intervals\n",
    "#     X_ij_hat_all, R_qk_ij = compute_estimates_and_residuals_irregular_times(lambda_h, t_measure_all[:,:-1], Q, K, V, self.args)\n",
    "#     mat_exp = batched_complex_exp(lambda_h.squeeze(1).unsqueeze(0) * (t_measure_all[:,-1] - t_measure_all[:,-2]).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1))\n",
    "#     K_exp2 = None\n",
    "\n",
    "# if self.args.tanh == 0:\n",
    "#     P_ij, nu = compute_precision(lambda_h, lambda_Omega, lambda_Omega0, lambda_Gamma, K_exp2, t_measure_all[:,:-1], self.args, R_qk_ij=R_qk_ij, alpha_nu=self.alpha_nu, beta_nu=self.beta_nu, lambda_C=self.lambda_C)\n",
    "# else:\n",
    "#     P_ij, nu = compute_precision_tanh(lambda_h, lambda_Omega, lambda_Omega0, lambda_Gamma, K_exp2, t_measure_all[:,:-1], self.args, R_qk_ij=R_qk_ij, alpha_nu=self.alpha_nu, beta_nu=self.beta_nu, lambda_C=self.lambda_C)\n",
    "\n",
    "# # Compute unnormalized attention matrix\n",
    "# mahalanobis_distance = P_ij * (R_qk_ij[:,0]**2 + R_qk_ij[:,1]**2)\n",
    "# denom = (1 + nu*torch.sum(mahalanobis_distance, axis=3, keepdims = True))\n",
    "# A_ij = P_ij / denom\n",
    "\n",
    "# A_ij = A_ij * self.causal_mask # Apply causal mask to attention matrix\n",
    "# X_ij_hat_all = X_ij_hat_all * self.causal_mask # Mask out estimates backward in time (not strictly necessary but useful larter for visualization)\n",
    "\n",
    "# # Normalize attention\n",
    "# S_ij = torch.sum(A_ij, axis=2, keepdims = True)\n",
    "# Q_ij = A_ij / S_ij\n",
    "\n",
    "# # Compute Hadamard product and sum to get estimate in diagonalized space\n",
    "# est_v = torch.sum(Q_ij.unsqueeze(1) * X_ij_hat_all,axis=3)\n",
    "\n",
    "# # Add residual connection\n",
    "# est_eigenbasis = est_v # No residual connection\n",
    "# #     est_e = self.args.alpha*est_v + self.args.beta*V # JUST FOR TESTING\n",
    "# #     est_e = est_v + self.alpha*(est_v - V) # JUST FOR TESTING\n",
    "# #     est_e = est_v + R\n",
    "# #     est_e = est_v + batched_complex_matmul(W_r, est_v - V)\n",
    "\n",
    "# # Multiply by output matrix to get estimate\n",
    "# #     est = batched_complex_matmul(W_e,est_eigenbasis)\n",
    "# est = batched_complex_matmul(W_e,est_eigenbasis) + W_e_b\n",
    "# #     est = batched_complex_matmul(W_p,est_eigenbasis)\n",
    "\n",
    "# # Get prediction in diagonalized space\n",
    "# #     pred_p = batched_complex_hadamard(mat_exp, est_e)\n",
    "# #     pred_p = batched_complex_hadamard(lambda_h, est_e)*(self.args.n * self.args.dt) + est_e # JUST FOR TESTING\n",
    "# #     pred_p = batched_complex_hadamard(mat_exp, V) # JUST FOR TESTING\n",
    "# #     pred_p = batched_complex_hadamard(lambda_h, V)*(self.args.n * self.args.dt) + V # JUST FOR TESTING\n",
    "# if self.args.t_equal == 1: # If equal time intervals\n",
    "#     pred_p = batched_complex_hadamard(mat_exp, est_eigenbasis)\n",
    "# else:\n",
    "#     pred_p = batched_complex_hadamard_full(mat_exp.unsqueeze(2), est_eigenbasis)\n",
    "\n",
    "# # Multiply by output matrix to get output prediction\n",
    "# #     pred = batched_complex_matmul(self.W_p, pred_p)\n",
    "# #     pred = batched_complex_matmul(W_p, pred_p)\n",
    "# pred = batched_complex_matmul(W_p, pred_p) + W_p_b\n",
    "# #     pred = batched_complex_matmul(self.W_p, batched_complex_hadamard(lambda_h, X_v))*self.args.dt + X_v # JUST FOR TESTING\n",
    "\n",
    "# # Output is a linear combination of estimate and prediction\n",
    "# out = self.args.delta*pred + self.args.eta*est\n",
    "# #     out = self.delta*pred + self.eta*est\n",
    "# #     out = pred + est\n",
    "\n",
    "# est = est.squeeze(-1)\n",
    "# out = out.squeeze(-1)\n",
    "# X_ij_hat_all = X_ij_hat_all.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5002b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1, 64, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_h = compute_lambda_h(lambda1, args).view(2,num_heads,1,head_dim,1)\n",
    "lambda_h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3d7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
